<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Andrey Voynov</title>

    <meta name="author" content="Andrey Voynov">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:790px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Andrey Voynov
                </p>
                <p>I'm a researcher at Google in Tel Aviv, focusing on creative imagenery.
                </p>
                <p>
                  I work in <a href="https://blog.google/products/photos/google-photos-features-pixel-8-pro/">Creative Camera</a> focusing on new capabilities of generative models. I also host visiting student researchers and collaborate with academic groups.
                  I have math background and defeated my PhD from Moscow State University in 2014. Before joining Google in 2022
                  I worked as a Research Scientist in <a href="https://research.yandex.com/">Yandex Research</a> and also participated in its autonomouse car developement.
                </p>
                <p style="text-align:center">
                  <a href="mailto:an.voynov@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=imBjSgUAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/kusichan">ùïè</a> &nbsp;/&nbsp;
                  <a href="https://github.com/anvoynov">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/avoynov.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/avoynov.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <h2>Research</h2>
      <p>
        I'm interested in computer vision and deep learning, in particular, images generative models and unsupervised learning. My current research is mostly focused on new capabilities of visual generative models for creativity.
        My math research was in the intersection of convex geometry and functional analysis.
      </p>
    </td>
  </tr>
</tbody></table>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/renoise.jpg" alt="clean-usnob" width="160" height="160">
    </td>
    <td width="75%" valign="middle">
      <a href="https://arxiv.org/abs/2403.14602">
        <span class="papertitle">ReNoise: Real Image Inversion Through Iterative Noising</span>
      </a>
      <br>
      <a href="https://garibida.github.io/danielgaribi/">Daniel Garibi</a>,
      <a href="https://orpatashnik.github.io/">Or Patashnik</a>,
      <strong>Andrey Voynov</strong>,
      <a href="https://www.elor.sites.tau.ac.il/">Hadar Averbuch-Elor</a>,
      <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>,
      <br>
      <em>ECCV</em>, 2024
      <br>
      <a href="https://garibida.github.io/ReNoise-Inversion/">project page</a>
      /
      <a href="https://huggingface.co/spaces/garibida/ReNoise-Inversion">demo</a>
      /
      <a href="https://arxiv.org/abs/2403.14602">arXiv</a>
      <p>Euler forward method is used to enable more accurate diffusion inversion.</p>
    </td>
  </tr>

  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/anylens.jpg" alt="clean-usnob" width="160" height="160">
    </td>
    <td width="75%" valign="middle">
      <a href="https://arxiv.org/abs/2311.17609">
        <span class="papertitle">Curved Diffusion: A Generative Model With Optical Geometry Control</span>
      </a>
      <br>
      <strong>Andrey Voynov</strong>,
      <a href="https://amirhertz.github.io/">Amir Hertz</a>,
      <a href="https://scholar.google.com/citations?user=uiFoSGMAAAAJ&hl=en">Moab Arar</a>,
      <a>Shlomi Fruchter</a>,
      <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>,
      <br>
      <em>ECCV</em>, 2024
      <br>
      <a href="https://anylens-diffusion.github.io/">project page</a>
      /
      <a href="https://arxiv.org/abs/2311.17609">arXiv</a>
      <p>Diffusion model with extra camera curvature conditioning implemented with either Riemannian metric tensor, or per-pixel coordinates conditioning.</p>
    </td>
  </tr>

  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/style_aligned.png" alt="clean-usnob" width="160" height="160">
    </td>
    <td width="75%" valign="middle">
      <a href="https://arxiv.org/abs/2312.02133">
        <span class="papertitle">Style aligned image generation via shared attention</span>
      </a>
      <br>
      <a href="https://amirhertz.github.io/">Amir Hertz*</a>,
      <strong>Andrey Voynov*</strong>,
      <a>Shlomi Fruchter</a>,
      <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>
      <br>
      <em>CVPR</em>, 2024 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
      <br>
      <a href="https://style-aligned-gen.github.io/">project page</a>
      /
      <a href="https://github.com/google/style-aligned/">code</a>
      /
      <a href="https://arxiv.org/abs/2312.02133">arXiv</a>
      <p>Cross-batch shared self-attention makes a diffusion model generate images with aligned styles.</p>
    </td>
  </tr>


  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/concept_tree.jpg" alt="clean-usnob" width="160" height="160">
    </td>
    <td width="75%" valign="middle">
      <a href="https://arxiv.org/abs/2305.18203">
        <span class="papertitle">Concept decomposition for visual exploration and inspiration</span>
      </a>
      <br>
      <a href="https://yael-vinker.github.io/website/">Yael Vinker</a>,
      <strong>Andrey Voynov</strong>,
      <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>,
      <a href="https://faculty.runi.ac.il/arik/site/index.asp">Ariel Shamir</a>
      <br>
      <em>SIGGRAPH-Asia, Journal track</em>, 2023 &nbsp <font color="red"><strong>(Best Paper Award)</strong></font>
      <br>
      <a href="https://inspirationtree.github.io/inspirationtree/">project page</a>
      /
      <a href="https://github.com/google/inspiration_tree">code</a>
      /
      <a href="https://arxiv.org/abs/2305.18203">arXiv</a>
      <p>Diffusion model personalization forms a binary tree of a visual concept decomposition.</p>
    </td>
  </tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/sketch_guided.jpg" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://dl.acm.org/doi/abs/10.1145/3588432.3591560">
      <span class="papertitle">Sketch-guided text-to-image diffusion models</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>,
    <a href="https://kfiraberman.github.io/">Kfir Aberman</a>,
    <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>
    <br>
    <em>SIGGRAPH</em>, 2023
    <br>
    <a href="https://sketch-guided-diffusion.github.io/">project page</a>
    /
    <a href="https://arxiv.org/abs/2211.13752">arXiv</a>
    <p>Small MLP performs gradient guidance over intermediate diffusion features for sketch-to-image generation.</p>
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/p_plus.png" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://arxiv.org/abs/2303.09522">
      <span class="papertitle">P+: Extended Textual Conditioning in Text-to-Image Generation</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>,
    <a>Qingyan Chu</a>,
    <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>,
    <a href="https://kfiraberman.github.io/">Kfir Aberman</a>
    <br>
    <em>arXiv</em>, 2023
    <br>
    <a href="https://prompt-plus.github.io/">project page</a>
    /
    <a href="https://arxiv.org/abs/2303.09522">arXiv</a>
    <p>Different prompts are injected to different cross-attention layers that majorly improves textual inversion and allows appearance mixing.</p>
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/www.png" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://arxiv.org/abs/2202.08937">
      <span class="papertitle">When, Why, and Which Pretrained GANs Are Useful?</span>
    </a>
    <br>
    <a>Timofey Grigoryev*</a>,
    <strong>Andrey Voynov*</strong>,
    <a href="https://scholar.google.com/citations?user=Zi5KiDsAAAAJ&hl=en">Artem Babenko</a>
    <br>
    <em>ICLR</em>, 2022
    <br>
    <a href="https://arxiv.org/abs/2202.08937">arXiv</a>
    /
    <a href="https://github.com/yandex-research/gan-transfer">code</a>
    <p>Recall is what important for GAN initialization, and Imagenet-pretrained StyleGAN is a good choice.</p>
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/diffusion_segmentation.png" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://arxiv.org/abs/2112.03126">
      <span class="papertitle">Label-efficient semantic segmentation with diffusion models</span>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=NiPmk8oAAAAJ">Dmitry Baranchuk</a>,
    <a href="https://scholar.google.com/citations?user=NiPmk8oAAAAJ">Ivan Rubachev</a>,
    <strong>Andrey Voynov</strong>,
    <a href="https://scholar.google.com/citations?user=GS5HTlkAAAAJ&hl=en">Valentin Khrulkov</a>,
    <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ">Artem Babenko</a>
    <br>
    <em>ICLR</em>, 2022
    <br>
    <a href="https://arxiv.org/abs/2112.03126">arXiv</a>
    /
    <a href="https://github.com/yandex-research/ddpm-segmentation">code</a>
    <p>Diffusion model intermediate features are used for few-shot segmentation.</p>
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/gan_segmentation.jpg" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://proceedings.mlr.press/v139/voynov21a.html">
      <span class="papertitle">Object segmentation without labels with large-scale generative models</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>,
    <a href="https://scholar.google.com/citations?user=4UYqtFYAAAAJ">Stanislav Morozov</a>,
    <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ">Artem Babenko</a>
    <br>
    <em>ICML</em>, 2021
    <br>
    <a href="https://arxiv.org/abs/2006.04988">arXiv</a>
    /
    <a href="https://github.com/anvoynov/BigGANsAreWatching">code</a>
    <p>Background-segmentation latent direction of BigBiGAN produces synthetic data for unsupervised foreground segmentation learning.</p>
  </td>
</tr>



<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/navigan.jpg" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cherepkov_Navigating_the_GAN_Parameter_Space_for_Semantic_Image_Editing_CVPR_2021_paper.pdf">
      <span class="papertitle">Navigating the GAN parameter space for semantic image editing</span>
    </a>
    <br>
    Anton Cherepkov,
    <strong>Andrey Voynov</strong>,
    <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ">Artem Babenko</a>
    <br>
    <em>CVPR</em>, 2021
    <br>
    <a href="https://arxiv.org/abs/2011.13786">arXiv</a>
    /
    <a href="https://github.com/yandex-research/navigan">code</a>
    <p>Finding StyleGAN weights shifts that induces interpretable images editing.</p>
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/swav_fid.png" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://openreview.net/pdf?id=NeRdBeTionN">
      <span class="papertitle">On Self-Supervised Image Representations for GAN Evaluation</span>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=4UYqtFYAAAAJ">Stanislav Morozov</a>,
    <strong>Andrey Voynov</strong>,
    <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ">Artem Babenko</a>
    <br>
    <em>ICLR</em>, 2021  &nbsp <font color="blue"><strong>(Spotlight)</strong></font>
    <br>
    <a href="https://openreview.net/forum?id=NeRdBeTionN">paper</a>
    /
    <a href="https://github.com/stanis-morozov/self-supervised-gan-eval">code</a>
    <p>Self-supervised pretrained backbones are shown to be better features extractors for GANs evaluation.</p>
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/gan_latent_space.jpg" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://proceedings.mlr.press/v119/voynov20a.html">
      <span class="papertitle">Unsupervised Discovery of Interpretable Directions in the GAN Latent Space</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>,
    <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ">Artem Babenko</a>
    <br>
    <em>ICML</em>, 2020
    <br>
    <a href="https://arxiv.org/abs/2002.03754">arXiv</a>
    /
    <a href="https://github.com/anvoynov/GANLatentDiscovery">code</a>
    <p>An unsupervised method to find interpretable directions in a GAN latent space.</p>
  </td>
</tr>



<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src="images/rpgan.jpg" alt="clean-usnob" width="160" height="160">
  </td>
  <td width="75%" valign="middle">
    <a href="https://arxiv.org/abs/1912.10920">
      <span class="papertitle">RPGAN: GANs Interpretability via Random Routing</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>,
    <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ">Artem Babenko</a>
    <br>
    <em>arXiv</em>, 2019
    <br>
    <a href="https://arxiv.org/abs/1912.10920">arXiv</a>
    /
    <a href="https://github.com/anvoynov/RandomPathGAN">code</a>
    <p>A GAN with a generator composed of a sequence of randomly-chosen layers.</p>
  </td>
</tr>



<tr>
<td>
<h3>Math Papers</h3> 
</td>
<br>
<td width="75%" valign="middle">
<p>
  My math research was primarly focused on functional analysis, random matrices semigroups, and convex geometry.
  I had a pleasure to have <a href="https://scholar.google.com/citations?user=pgEzSSYAAAAJ">Vladimir Protasov</a> as my PhD advisor.
  In all the papers below the authors order is alphabetical.
</p>  
</td>
</tr>

<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
  </td>
  <td width="75%" valign="middle">
    <a href="https://www.sciencedirect.com/science/article/pii/S0024379516304864">
      <span class="papertitle">Matrix semigroups with constant spectral radius</span>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=pgEzSSYAAAAJ">Vladimir Protasov</a>,
    <strong>Andrey Voynov</strong>
    <br>
    <em>Linear Algebra and its Applications</em>, (513, 376-408) 2017
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
  </td>
  <td width="75%" valign="middle">
    <a href="https://iopscience.iop.org/article/10.1070/SM2015v206n07ABEH004483>
      <span class="papertitle">Compact noncontraction semigroups of affine operators</span>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=pgEzSSYAAAAJ">Vladimir Protasov</a>,
    <strong>Andrey Voynov</strong>
    <br>
    <em>Sbornik: Mathematics</em>, 206 (7), 921, 2015
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
  </td>
  <td width="75%" valign="middle">
    <a href="https://iopscience.iop.org/article/10.1070/SM2013v204n08ABEH004332/meta">
      <span class="papertitle">On the structure of self-affine convex bodies</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>
    <br>
    <em>Sbornik: Mathematics</em>, 204 (8), 1122, 921, 2013
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
  </td>
  <td width="75%" valign="middle">
    <a href="https://www.sciencedirect.com/science/article/pii/S0024379513003017">
      <span class="papertitle">Shortest positive products of nonnegative matrices</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>
    <br>
    <em>Linear Algebra and its Applications</em>, 439 (6), 1627-1634, 2013
  </td>
</tr>

<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
  </td>
  <td width="75%" valign="middle">
    <a href="https://www.sciencedirect.com/science/article/pii/S0024379512002005">
      <span class="papertitle">Sets of nonnegative matrices without positive products</span>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=pgEzSSYAAAAJ">Vladimir Protasov</a>,
    <strong>Andrey Voynov</strong>
    <br>
    <em>Linear Algebra and its Applications</em>, 437 (3), 749-765, 2012
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
  </td>
  <td width="75%" valign="middle">
    <a href="https://link.springer.com/article/10.1134/S0081543811080207">
      <span class="papertitle">A counterexample to Valette‚Äôs conjecture</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>
    <br>
    <em>Proceedings of the Steklov Institute of Mathematics</em>,  275 (1), 290-292, 2011
  </td>
</tr>


<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
  </td>
  <td width="75%" valign="middle">
    <a href="https://iopscience.iop.org/article/10.1070/SM2011v202n10ABEH004193">
      <span class="papertitle">Self-affine polytopes. Applications to functional equations and matrix theory</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>
    <br>
    <em>Sbornik: Mathematics</em>,  202 (10), 1413, 2011
  </td>
</tr>

<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
  </td>
  <td width="75%" valign="middle">
    <a href="https://link.springer.com/article/10.1134/S0001434611070042">
      <span class="papertitle">On compact sets with a certain affine invariant</span>
    </a>
    <br>
    <strong>Andrey Voynov</strong>
    <br>
    <em>Mathematical Notes</em>, 90, 32-36, 2011
  </td>
</tr>





  <!--  -->

    <!-- <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
          <source src="images/smerf.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/smerf.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function smerf_start() {
            document.getElementById('smerf_image').style.opacity = "1";
          }

          function smerf_stop() {
            document.getElementById('smerf_image').style.opacity = "0";
          }
          smerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://smerf-3d.github.io/">
          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
        </a>
        <br>
		<a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth*</a>,
		<a href="https://phogzone.com/">Peter Hedman*</a>,
		<a href="https://creiser.github.io/">Christian Reiser</a>,
		<a href="">Peter Zhizhin</a>,
		<a href="">Jean-Fran√ßois Thibert</a>,
        <a href="https://lucic.ai/">Mario Luƒçiƒá</a>,
        <a href="https://szeliski.org/">Richard Szeliski</a>,
		<strong>Jonathan T. Barron</strong>
        <br>
        <em>arXiv</em>, 2023
        <br>
        <a href="https://smerf-3d.github.io/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a>
        /
        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
        <br>
        <em>CVPR</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <p></p>
        <p>
        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
        </p>
      </td>
    </tr> -->

<!-- 
</tbody></table>
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
             -->
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This page template is based on Jon Barron's public academic website <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
